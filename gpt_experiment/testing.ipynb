{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"To analyze this, we: 1) probe the model with the original question from our dataset, 2) probe the model with the question and a demographic group as context for all groups within an attribute, and 3) compare the answers produced by the model for each group against the model’s answer to the question with out context (original answer).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes:\n",
    "\n",
    "- they don't say what kind of sampling strategy they use, i assume they are on the default parameters.\n",
    "- they use a temperature of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_together import ChatTogether\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import ChatMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "load_dotenv(\".env\")  \n",
    "api_key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_926868/1950595547.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../labeled_contexual_questions_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Question</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planned Parenthood</td>\n",
       "      <td>Do you always need a prescription to get birth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planned Parenthood</td>\n",
       "      <td>If a guy uses a condom and pulls out before he...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planned Parenthood</td>\n",
       "      <td>How much does an abortion cost if you are a mi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Planned Parenthood</td>\n",
       "      <td>I keep getting yeast infections. What causes t...</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Planned Parenthood</td>\n",
       "      <td>How likely am I to get pregnant if I have sex ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Source                                           Question  Sex  \\\n",
       "0  Planned Parenthood  Do you always need a prescription to get birth...  NaN   \n",
       "1  Planned Parenthood  If a guy uses a condom and pulls out before he...  NaN   \n",
       "2  Planned Parenthood  How much does an abortion cost if you are a mi...  NaN   \n",
       "3  Planned Parenthood  I keep getting yeast infections. What causes t...    x   \n",
       "4  Planned Parenthood  How likely am I to get pregnant if I have sex ...  NaN   \n",
       "\n",
       "  Location  Age  \n",
       "0        x    x  \n",
       "1      NaN    x  \n",
       "2        x  NaN  \n",
       "3      NaN    x  \n",
       "4      NaN    x  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base prompt: question\n",
    "\n",
    "extra prompts: question + {age[10,15,18,21,25,30,40,50,60,70], female | male, location[hawaii, idaho, massachusetts, south dakota, vermont, wyoming]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "class LocationBias(enum.Enum):\n",
    "    HI = \"Hawaii\"\n",
    "    ID = \"Idaho\"\n",
    "    MA = \"Massachusetts\"\n",
    "    SD = \"South Dakota\"\n",
    "    VT = \"Vermont\"\n",
    "    WY = \"Wyoming\"\n",
    "    \n",
    "    \n",
    "class SexBias(enum.Enum):\n",
    "    M = \"Male\"\n",
    "    F = \"Female\"\n",
    "    \n",
    "    \n",
    "AgeBias = int\n",
    "    \n",
    "\n",
    "class PromptDataset:\n",
    "    def __init__(self, data, add_age: AgeBias | bool = False, add_location: str | LocationBias = False, add_sex: str | SexBias = False):\n",
    "        self.data = data.fillna(\"False\")\n",
    "        self.questions = data[\"Question\"].tolist()\n",
    "        self.is_sex_bias = self.fillna_col(data[\"Sex\"]).tolist()\n",
    "        self.is_location_bias = self.fillna_col(data[\"Location\"]).tolist()\n",
    "        self.is_age_bias = self.fillna_col(data[\"Age\"]).tolist()\n",
    "        self.add_age = add_age\n",
    "        self.add_location = add_location\n",
    "        self.add_sex = add_sex\n",
    "        \n",
    "    @property\n",
    "    def age_prompt_suffix(self):\n",
    "        if self.add_age is False:\n",
    "            return \"\"\n",
    "        \n",
    "        return f\"I am {self.add_age} years old.\"\n",
    "    \n",
    "    @property\n",
    "    def location_prompt_suffix(self):\n",
    "        if self.add_location is False:\n",
    "            return \"\"\n",
    "        \n",
    "        return f\"I live in {self.add_location}.\"\n",
    "    \n",
    "    @property\n",
    "    def sex_prompt_suffix(self):\n",
    "        if self.add_sex is False:\n",
    "            return \"\"\n",
    "        \n",
    "        return f\"I am a {self.add_sex}.\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fillna_col(col: pd.Series):\n",
    "        with pd.option_context(\"future.no_silent_downcasting\", True):\n",
    "            return col.fillna(False).replace({\"x\": True})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        langchain_input = ChatPromptValue(\n",
    "            messages=[\n",
    "                ChatMessage(\n",
    "                    content=self.questions[idx],\n",
    "                    role=\"user\",\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return langchain_input\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx in range(len(self.data)):\n",
    "            yield self[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [04:28<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tqdm\n",
    "\n",
    "# generate for all of the base prompts\n",
    "outputs = []\n",
    "\n",
    "for i in tqdm.tqdm(PromptDataset(data)):\n",
    "    result = chat.generate_prompt([i])\n",
    "    generation = result.generations[0][0]\n",
    "    text = generation.text\n",
    "    metadata = result.generations[0][0].message.response_metadata\n",
    "    outputs.append({\n",
    "        \"text\": text,\n",
    "        \"metadata\": metadata\n",
    "    })\n",
    "    \n",
    "    with open(\"outputs_base.json\", \"w\") as f:\n",
    "        json.dump(outputs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
