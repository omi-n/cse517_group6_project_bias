{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"To analyze this, we: 1) probe the model with the original question from our dataset, 2) probe the model with the question and a demographic group as context for all groups within an attribute, and 3) compare the answers produced by the model for each group against the modelâ€™s answer to the question with out context (original answer).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes:\n",
    "\n",
    "- they don't say what kind of sampling strategy they use, i assume they are on the default parameters.\n",
    "- they use a temperature of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import ChatTogether\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import ChatMessage\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatTogether(\n",
    "    together_api_key=os.environ[\"TG_KEY\"],\n",
    "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../labeled_contexual_questions_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base prompt: question\n",
    "\n",
    "extra prompts: question + {age[10,15,18,21,25,30,40,50,60,70], female | male, location[hawaii, idaho, massachusetts, south dakota, vermont, wyoming]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "class LocationBias(enum.Enum):\n",
    "    HI = \"Hawaii\"\n",
    "    ID = \"Idaho\"\n",
    "    MA = \"Massachusetts\"\n",
    "    SD = \"South Dakota\"\n",
    "    VT = \"Vermont\"\n",
    "    WY = \"Wyoming\"\n",
    "    \n",
    "    \n",
    "class SexBias(enum.Enum):\n",
    "    M = \"Male\"\n",
    "    F = \"Female\"\n",
    "    \n",
    "    \n",
    "AgeBias = int\n",
    "    \n",
    "\n",
    "class PromptDataset:\n",
    "    def __init__(self, data, add_age: AgeBias | bool = False, add_location: str | LocationBias = False, add_sex: str | SexBias = False):\n",
    "        self.data = data.fillna(\"False\")\n",
    "        self.questions = data[\"Question\"].tolist()\n",
    "        self.is_sex_bias = self.fillna_col(data[\"Sex\"]).tolist()\n",
    "        self.is_location_bias = self.fillna_col(data[\"Location\"]).tolist()\n",
    "        self.is_age_bias = self.fillna_col(data[\"Age\"]).tolist()\n",
    "        self.add_age = add_age\n",
    "        self.add_location = add_location\n",
    "        self.add_sex = add_sex\n",
    "        \n",
    "    @property\n",
    "    def age_prompt_suffix(self):\n",
    "        if self.add_age is False:\n",
    "            return \"\"\n",
    "        \n",
    "        return f\"I am {self.add_age} years old.\"\n",
    "    \n",
    "    @property\n",
    "    def location_prompt_suffix(self):\n",
    "        if self.add_location is False:\n",
    "            return \"\"\n",
    "        \n",
    "        return f\"I live in {self.add_location}.\"\n",
    "    \n",
    "    @property\n",
    "    def sex_prompt_suffix(self):\n",
    "        if self.add_sex is False:\n",
    "            return \"\"\n",
    "        \n",
    "        return f\"I am a {self.add_sex}.\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fillna_col(col: pd.Series):\n",
    "        with pd.option_context(\"future.no_silent_downcasting\", True):\n",
    "            return col.fillna(False).replace({\"x\": True})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        langchain_input = ChatPromptValue(\n",
    "            messages=[\n",
    "                ChatMessage(\n",
    "                    content=self.questions[idx],\n",
    "                    role=\"user\",\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return langchain_input\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx in range(len(self.data)):\n",
    "            yield self[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tqdm\n",
    "\n",
    "# generate for all of the base prompts\n",
    "outputs = []\n",
    "\n",
    "for i in tqdm.tqdm(PromptDataset(data)):\n",
    "    result = chat.generate_prompt([i])\n",
    "    generation = result.generations[0][0]\n",
    "    text = generation.text\n",
    "    metadata = result.generations[0][0].message.response_metadata\n",
    "    outputs.append({\n",
    "        \"text\": text,\n",
    "        \"metadata\": metadata\n",
    "    })\n",
    "    \n",
    "    with open(\"outputs_base.json\", \"w\") as f:\n",
    "        json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
